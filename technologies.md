## Модели для сегментации и/или распознавания объектов:

### FlowSAM
- [Project Page](https://www.robots.ox.ac.uk/~vgg/research/flowsam/)
- [GitHub](https://github.com/Jyxarthur/flowsam)
- [Paper](https://arxiv.org/abs/2404.12389)
- [Data](https://drive.google.com/drive/folders/1tmDq_vG_BvY5po40Ux5OBds1avUM_CbR)

### YOLO Models
* [Ultralytics Page](https://docs.ultralytics.com/models/)
* [Paper](https://arxiv.org/abs/1506.02640)
* [What is YOLO? The Ultimate Guide 2024](https://blog.roboflow.com/guide-to-yolo-models/) 
#### FastSAM
The Fast Segment Anything Model (FastSAM) is a novel, **real-time CNN-based solution for the Segment Anything task**. This task is designed to segment any object within an image based on various possible user interaction prompts. FastSAM significantly reduces computational demands while maintaining competitive performance, making it a practical choice for a variety of vision tasks.
#### RT-DETR
**Real-Time Detection** Transformer (RT-DETR), developed by Baidu, is a cutting-edge end to-end object detector that provides real-time performance while maintaining high accuracy. It leverages the power of Vision Transformers (ViT) to efficiently process multiscale features by decoupling intra-scale interaction and cross-scale fusion. RT-DETR is highly adaptable, supporting flexible adjustment of inference speed using different decoder layers without retraining. The model excels on accelerated backends like CUDA with TensorRT, outperforming many other real-time object detectors.

### Detectron Models
* Project Page
* Paper
* [GitHub (Detectron 2)](https://github.com/facebookresearch/detectron2)

### MobileNET / MobileNet-SSD
* Project Page
* Paper
* [GitHub](https://github.com/chuanqi305/MobileNet-SSD)

### DeepLab
* Project Page
* Paper

### ViTDet
* Project Page
* Paper

### Swin Transformer
* [Paper](https://arxiv.org/pdf/2103.14030)

### Faster R-CNN
* Paper

### RetinaNet
* Paper

## Дополнительно



